## CVPR 2017 相关

### transfer learning

#### [Borrowing Treasures From the Wealthy: Deep Transfer Learning Through Selective Joint Fine-Tuning, Weifeng Ge, Yizhou Yu](https://arxiv.org/pdf/1702.08690.pdf)
这篇文章是做迁移学习，当源任务和目标任务类似时，如何将源任务的大数据集用到目标任务的小数据集中，以更好补充数据，实现目标任务。
source源任务——大规模数据集
target目标任务——小规模数据集，
数据集是图像，源任务和目标任务共享卷积层特征，从大规模数据中找出低层特征和小规模数据集中低层特征类似(histogram-based, 特征的KL散度作相似度度量)的图像，一起加入训练。一方面两个任务共享卷积层参数防止过拟合，另一方面，针对于目标任务选择了更多类似图片，这低层卷积层核函数提取特征对于目标任务更具有鲁棒性。
为什么选低层特征，是因为我们认为这些低层特征决定了高层特征，而高层特征可能具有不同的语义信息。（我想到一个例子，比方说，源任务和目标任务低层特征具有某种边缘特性，那么我们去找具有类似边缘特性的图像扩充目标任务数据集，可以减少其他和目标任务无关的特征影响，保持新增样本在目标任务中发挥作用）


### cross, multimodal
#### [Split-BrainAutoencoders:UnsupervisedLearningby Cross-Channel Prediction, Richard Zhang, Phillip Isola, Alexei A. Efros](https://arxiv.org/pdf/1611.09842.pdf)
这篇文章立足于传统自编码技术，将神经网络分割为两个子网络，实现输入数据不同通道间信息的转换，以实现无监督数据的预训练。
这个工作是无监督学习方向的一个例子。即我们希望得到数据的一组特征，可以方便地转换适用于多个任务。传统方法通过自编码网络取网络的前一部分，这个方法并非取神经网络的前一些层，避免无法获得高层语义信息，而是将网络分割为不同通道（两个）的子网络，两个子网络是互补关系，像人的左右脑。
这个方法同 自编码网络、去噪自编码、上下文编码、交叉通道编码方法进行了对比，主要比较是否可用于输入信号的重建、预测。在Imagenet、Places、Pascal数据集进行了测试。

#### [Deep Heterogeneous Face Recognition Networks Based on Cross-Modal Distillation and an Equitable Distance Metric, Christopher Reale, Hyungtae Lee, Heesung Kwon]()
这篇文章网上还没有，但是觉得挺有意思的

The More You Know: Using Knowledge Graphs for Image Classification Kenneth Marino, Ruslan Salakhutdinov, Abhinav Gupta
这篇文章是基于Gated Graph Sequence Neural Network，将其应用到多标签图像分类问题。
思路来源是GNN，Graph Neural Network用以描述图结构的数据-》

#### Convolutional Neural Network Architecture for Geometric Matching Ignacio Rocco, Relja ArandjeloviÄ‡, Josef Sivic(http://www.di.ens.fr/willow/research/cnngeometric/)
不知道能不能用到地图匹配上。
哦 好像没啥用，主要是做一个轻微的仿射变换后的图像与原图像匹配

Diversified Texture Synthesis With Feed-Forward Networks
Yijun Li, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, Ming-Hsuan Yang
卷积神经网络实现图像纹理风格迁移。
网络主要由并行的生成式网络和选择网络，损失函数采用纹理损失和多样性损失。这个工作比较有意思的就是做了多种纹理风格的迁移。

Multi-Scale FCN With Cascaded Instance Aware Segmentation for Arbitrary Oriented Word Spotting in the Wild
Dafang He, Xiao Yang, Chen Liang, Zihan Zhou, Alexander G. Ororbi II, Daniel Kifer, C. Lee Giles

Regularization for Online Ensemble Tracking With Convolutional Neural Networks
Bohyung Han, Jack Sim, Hartwig Adam
说不定可以借鉴这里面正则化的方法

[Fully Convolutional Self-Similarity for Dense Semantic Correspondence](https://arxiv.org/pdf/1702.00926.pdf)
Seungryong Kim, Dongbo Min, Bumsub Ham, Sangryul Jeon, Stephen Lin, Kwanghoon Sohn
可以借鉴这里通过卷积层相似度给出loss，训练找到图片相似的地方。这里认为，同一类物体图片尽管在特征上颜色、梯度等方面有差异，但是局部区域的自相似度（local self-similarity）是保持一致的。

Nonnegative Matrix Underapproximation for Robust Multiple Model Fitting
Mariano Tepper, Guillermo Sapiro
非负矩阵分解用于图像中模型匹配，


Spindle Net: Person Re-Identification With Human Body Region Guided Feature Decomposition and Fusion
Haiyu Zhao, Maoqing Tian, Shuyang Sun, Jing Shao, Junjie Yan, Shuai Yi, Xiaogang Wang, Xiaoou Tang
看一看，没找到这篇，找到下面这篇

#### [Person Re-Identification by Deep Joint Learning of Multi-Loss Classification](https://arxiv.org/pdf/1705.04724.pdf)
这篇文章处理人体身份识别问题时，将局部信息和全局信息作为两个网络，采用 LASSO 进行稀疏化。
这篇文章的贡献点在于提出了Joint Learning Multi-Loss，不仅将全局特征及局部特征融合，而且加入历史信息？，最后还提供了稀疏化的方法。
他们处理的方式没有什么融合，就是设计了一个multi-loss进行训练，我们能否在某一层融合之后，一方面对该层的多个局部特征分别训练，另一方面对所有特征一起训练
觉得可以借鉴的就是稀疏化以及如何设计multi-loss

Improving Interpretability of Deep Neural Networks With Semantic Information
Yinpeng Dong, Hang Su, Jun Zhu, Bo Zhang
加入语义信息和我们加入声音信息是不是类似的
清华张博老师做的，dongyinpeng，将语义信息加入网络，使得网络具有更好的可解释性。还是image caption的思路，CNN提取特征，同主题词一起投入RNN训练。

Automatic Understanding of Image and Video Advertisements
做广告的，主要是提出了一个数据集。声音和视频没有对应关系。
(64,832 images with 3 or 5 question-answer pairs per image) 问题是 what and why

#### [From Red Wine to Red Tomato: Composition With Context]()
Ishan Misra, Abhinav Gupta, Martial Hebert
红酒的红，红番茄的红，一样的红，不一样的意义
这篇文章讲的是利用上下文进行概念分解组合。主要是做了属性和物体概念的划分和组合，主语宾语和动词。
咱们如果做这个任务，你就是材质和功能分开？比方说训练了金属运动水杯、塑料运动水杯、塑料保温杯，可以对金属保温杯进行训练。

Conditional Similarity Networks
学习图像之间的相似性。以往相似性学习是将图像映射到特征空间，按照特征空间里向量间的距离来度量。这样的话，往往衡量的是某种相似性，比方说颜色或者哪种性质

Crossing Nets: Combining GANs and VAEs With a Shared Latent Space for Hand Pose Estimation
Chengde Wan, Thomas Probst, Luc Van Gool, Angela Yao
GAN，手势识别，跟我们关系不大。

#### [Cross-View Image Matching for Geo-Localization in Urban Environments](https://arxiv.org/pdf/1703.07815.pdf)
这个就是老板说的卫星图与拍摄图的匹配对应。。
Google Street View Dataset
1, 586, 1, 324 and 5, 941 GPS locations in Pittsburg, Orlando and Manhattan, respectively. We utilize DualMaps 1 to generate side-by-side street view and bird’s eye view images at each GPS location with the same heading direction
这里着重的是图像的特征提取与检索。咱们能不能设计端对端的网络结构，用于训练学习卫星图与拍摄图位置对应。

Fast Video Classification via Adaptive Cascading of Deep Models
Haichen Shen, Seungyeop Han, Matthai Philipose, Arvind Krishnamurthy
视频快速分类

[FastMask: Segment Multi-Scale Object Candidates in One Shot](https://pdfs.semanticscholar.org/031d/4a3940011f6be69a7e24f1a04980482ee477.pdf)
Hexiang Hu, Shiyi Lan, Yuning Jiang, Zhimin Cao, Fei Sha
场景分割，提出了 weight-shared residual neck，权重共享残差，合理的处理了不同尺度下的特征。这个方法可以借鉴。

Generalized Semantic Preserving Hashing for N-Label Cross-Modal Retrieval
Devraj Mandal, Kunal N. Chaudhury, Soma Biswas
这个做的是检索问题。

A New Rank Constraint on Multi-View Fundamental Matrices, and Its Application to Camera Location Recovery
Soumyadip Sengupta, Tal Amir, Meirav Galun, Tom Goldstein, David W. Jacobs, Amit Singer, Ronen Basri
不同视角图像间关系导致的合成图像具有低秩特性？

A Multi-View Stereo Benchmark With High-Resolution Images and Multi-Camera Videos
Thomas SchÃ¶ps, Johannes L. SchÃ¶nberger, Silvano Galliani, Torsten Sattler, Konrad Schindler, Marc Pollefeys, Andreas Geiger

Hierarchical Multimodal Metric Learning for Multimodal Classification
Heng Zhang, Vishal M. Patel, Rama Chellappa

#### Learning Cross-Modal Embeddings for Cooking Recipes and Food Images
Amaia Salvador, Nicholas Hynes, Yusuf Aytar, Javier Marin, Ferda Ofli, Ingmar Weber, Antonio Torralba
方法就是找图像的特征映射空间以及菜谱中原料的特征映射空间，Embedding空间的融合方法可以借鉴一下。

Deep Cross-Modal Hashing
Qing-Yuan Jiang, Wu-Jun Li
图像和文本的哈希映射。哈希有什么用？ 能用到我们工作吗

Multi-Modal Mean-Fields via Cardinality-Based Clamping
Pierre Baqué, FranÃ§ois Fleuret, Pascal Fua
理论文章，平均场，不明白。大致意思是改进了一下之前平均场导出CRF 条件随机场。

Multi-View 3D Object Detection Network for Autonomous Driving
Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, Tian Xia
电子系做的，这种图像处理相对简单一点，我们可以借鉴网络结构。

Multimodal Transfer: A Hierarchical Deep Convolutional Neural Network for Fast Artistic Style Transfer
Xin Wang, Geoffrey Oxholm, Da Zhang, Yuan-Fang Wang
多尺度快速风格迁移。这个也很有意思啊，直接把不同尺度的风格图像同网络得到的多个生成图对比，得到loss函数。

Fine-Grained Image Classification via Combining Vision and Language
Xiangteng He, Yuxin Peng
原来这么多精细划分的已经有数据集了，bird types／ dog species ／ plant breeds／ car types／ and aircraft models 
加入词，但是这个和音频没关系。～



