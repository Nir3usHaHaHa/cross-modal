## CVPR 2017

### transfer learning

#### [Borrowing Treasures From the Wealthy: Deep Transfer Learning Through Selective Joint Fine-Tuning, Weifeng Ge, Yizhou Yu](https://arxiv.org/pdf/1702.08690.pdf)
这篇文章是做迁移学习，当源任务和目标任务类似时，如何将源任务的大数据集用到目标任务的小数据集中，以更好补充数据，实现目标任务。
source源任务——大规模数据集
target目标任务——小规模数据集，
数据集是图像，源任务和目标任务共享卷积层特征，从大规模数据中找出低层特征和小规模数据集中低层特征类似(histogram-based, 特征的KL散度作相似度度量)的图像，一起加入训练。一方面两个任务共享卷积层参数防止过拟合，另一方面，针对于目标任务选择了更多类似图片，这低层卷积层核函数提取特征对于目标任务更具有鲁棒性。
为什么选低层特征，是因为我们认为这些低层特征决定了高层特征，而高层特征可能具有不同的语义信息。（我想到一个例子，比方说，源任务和目标任务低层特征具有某种边缘特性，那么我们去找具有类似边缘特性的图像扩充目标任务数据集，可以减少其他和目标任务无关的特征影响，保持新增样本在目标任务中发挥作用）


### cross, multimodal
#### [Split-BrainAutoencoders:UnsupervisedLearningby Cross-Channel Prediction, Richard Zhang, Phillip Isola, Alexei A. Efros](https://arxiv.org/pdf/1611.09842.pdf)
这篇文章立足于传统自编码技术，将神经网络分割为两个子网络，实现输入数据不同通道间信息的转换，以实现无监督数据的预训练。
这个工作是无监督学习方向的一个例子。即我们希望得到数据的一组特征，可以方便地转换适用于多个任务。传统方法通过自编码网络取网络的前一部分，这个方法并非取神经网络的前一些层，避免无法获得高层语义信息，而是将网络分割为不同通道（两个）的子网络，两个子网络是互补关系，像人的左右脑。
这个方法同 自编码网络、去噪自编码、上下文编码、交叉通道编码方法进行了对比，主要比较是否可用于输入信号的重建、预测。在Imagenet、Places、Pascal数据集进行了测试。

#### [Deep Heterogeneous Face Recognition Networks Based on Cross-Modal Distillation and an Equitable Distance Metric, Christopher Reale, Hyungtae Lee, Heesung Kwon]()
这篇文章网上还没有，但是觉得挺有意思的


#### 


